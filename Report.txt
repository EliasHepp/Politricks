# Social Informatics of Large Language Models - Project Report

Jakob Amann, 01/
Elias Gabriel Heppner, 01/1244414
Andri Rutschmann, 01/1246603

# Introduction

- here we motivate our project 
	- cambridge analytica and possible manipulation of people via large scale fake content about political actors
	- understanding gpt's understanding of political actors and their position regarding certain (well known) topics
- do we maybe have some theoretical groundwork for this project? LLMs are able to correctly depict the world... something like that

Explaining what we, as young  social data scientists, learn at university has probably never been as easy as it is today due to the viral fame of Large Language Models like ChatGPT. 'Well we just ask ChatGPT a bunch of questions and then analyse the respones.', is a hughely simplified answer, of course, but it conveys a general idea to all those that do not have the slightest clue what social data science might be about.
Now, of course we are prompting ChatGPT for stuff like 'How to write a project report?' or 'Write the introduction to our SILLM project paper?'. We rather try to phrase requests that help us understand how LLMs see, understand, and interpret our society.
Following this guideline the present report investigates how well GPT-4 understands the political stance of different German parliamentary politicians concerning three different political topics, of public interest: Migration, Covid-19, and the Ukraine War.
In light of scandals like Cambridge Analytica we feel that vigilance against attacks on domecracy is of utmost importance. The influence of fake news and social media on people's political behaviour is well documented [cite]. We are not going to further investigate this phenomenon here but we want to take a closer look on the generation of fake content. Up until a few months ago, puplicly available LLMs have not been able to convincingly generate human-like content [cite]. With the introduction of GPT-3, GPT-3.5, and now GPT-4, though, we have reached levels of yet unseen quality in the output of LLMs.
The power of (malicious) individuals using these resources towards their own goals has never been this potent. As we show in this report, generating convincing political content in the form of politicians' speeches, requires but access to OpenAI's ChatGPT-4 and some dedication towards the task. The potential to spread misinformation, that looks as though issued by democratically elected politicians, has thus increased manifold.
Another reason, less focussed on politics and more towards the understanding of LLMs, motivates this project. We aim to gain insights on how well GPT-4 knows German politicians. How familiar is it with their political agendas and their stance on different political issues. Understanding this piece of the cake might further our overall understanding of LLMs and, therefore, assist us in finding safe ways of dealing with a technology, that threatens to overtake the classic Google Search as number one approach of finding information online.
Using a selection of German parliamentary politicians from all six parties currently in parliament we prompt GPT-4 for speeches, mimicking the style and political stance of each individual politician regarding the topics of interest: Migration, Covid-19, and the Ukraine War. We then apply two different approaches to model the topics of these fake speeches. [here you guys have to write a short intro to each of your methods]. Using real speeches, given in parliament, we then compare the fakes to the originals, thereby gaining insights on GPT-4's workings.
This report documents our approach. First, we focus on which data we used, how we processed it, and what methods we used to analyse the resulting data set. We then present the results of our project. Finally, we discuss these findings in light of our research interest. 

# Data & Methods

- here we name opendiscourse
- we go into detail about manifestoberta and the PCA approach (do not forget citations! cite! cite! cite!)
- we also highlight how we processed the data (speeches) and how we choose topics and key actors to investigate

## Data Processing

- regex topic filtering for the speeches is still missing!

The opendiscourse speech data set contains a multitude of speeches, presumably every single speech given in German parliament dating back as far as 19XX [add year]. In some cases the data set is a bit to exhaustive for our purposes since it also includes questions and responses to individual speeches along with interjections and general anouncements of proceedings. Thus, the data set contains every speech we needed for our analysis but also quite a bit of noise which we were not interested in.
First of all we started by removing speeches that were not given by members of parliament (lobby representatives, etc. [is that correct?]) and were held before 2014 [correct?]. [Elias add some stuff about what you did].
After removing all non-politicians from the data set we took care of filtering the individual content. We used regular expressions in combination with a minimum token count to remove all data entries that did not document a speech. For the purpose of this analysis we defined a speech as a standalone piece of spoken opininon [does this make sense?]. More precisely, a speech is given by a single politician and does not need any context, given by others or the politican, to be valid and understandable. A question or interjection voiced as the result of some other contribution, for example, only makes sense in the context of the preceeding contribution. We would not classify this as a speech. On the other hand, a contribution that addresses the whole parliament, reflects the opinions and stance of an individual politician, and stands on its own without any context, is considered a speech.
Most of the time these contributions start by greeting the parliament members and the president of parliament and are rather lenghty in terms of word count. Using this pattern we constructed a regex filter that checks for different well established forms of greeting within the first one to two sentences of each contribution. We supplemented our regex by investigating the most common tokens in the first few sentences of all contributions and then manually added some of them to the filter. A very common way of referring to the other members of parliament in one's greeting, for example, is the use of "Kollegen" and "Kolleginnen" ("colleagues"). Using this regex filter we removed more than half of all contributions, shrinking the data set from 75,191 to 32,714 observations. This filter isn't perfect, though.
Sometimes, for example, a politician would answer a preceeding speech by greeting the whole of parliament and then giving a short response to the speech. We, therefore, implemented a minimum token cutoff of 300 tokens and removed all contributions that did not make the cut.[Argumentation correct?] We choose this threshold of 300 tokens after analyzing the distribution of content length and finding that most contributions ranged somewhere between 400-1,000 tokens. By removing the ones below 300 tokens we removed about 3,000 of our total 32,714 contributions. After manually checking a random sample of the remaining contributions for content we were satisfied to retain the remaining contributions as speeches.


## Politician Selection

In order to prompt GPT-4 for llm-generated speeches in the style of individual politicians we first had to come up with a selection of politicians. Ideally, we wanted each party to be represented by male and female politicians with both well and less known individuals. By themselves, these requirements would be pretty easily met but we also required the individual politicians to have held at least a few speeches concerning each topic. Otherwise comparing the llm-generated speeches to real ones would not have been possible.
We settled for a minimum of four speeches per topic. So each politician viable for sampling had to have held at least four speeches concerning migration, Covid-19, and the Ukrain war respectively. The number of four speeches per topic was chosen due to the fact that it was quite hard to find sufficient politicians per party that gave more than four speeches per topic. Even with this cutoff criteria it was impossible to sample an even 50/50 male/female politicians from each party. It seems that, at least in regards to our three topics of interest, the speakers in parliament for the AfD, CDU/CSU, and FDP are mostly male.
Still, we felt, that four speeches per topic would allow us to get a sufficiet estimate of the politicians real opinions and stance [is this a valid reason?]. Going lower than four speeches per politician and topic did not seem like a valid option. Estimating political opinion and stance from less than four speeches seemed unreasonable and imprecise.  
Filtering for all politicians that gave at least four speeches per topic we then manually selected four politicians per party. Where possible, we sampled two male and two female politicians and also tried to select one rather well known as well as one less known politician per gender. The resulting sample of politicians consists of 24 politicians, four each for AfD, CDU/CSU, FDP, Grüne, SPD, and DIE LINKE. Of those 16 are male and 8 are female. As mentioned above for the AfD, CDU/CSU, and FDP no female politicans met our sampling criteria with the exception of one female CDU/CSU politician. The full list of sampled politicians can be found in table [cite table].

[latex table]
-----

% Please add the following required packages to your document preamble:
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}
\begin{table}[]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
{\color[HTML]{000000} AfD}                      & {\color[HTML]{000000} CDU/CSU}                  & {\color[HTML]{000000} FDP}                      & {\color[HTML]{000000} Grüne}                    & {\color[HTML]{000000} SPD}                      & {\color[HTML]{000000} DIE LINKE}                \\ \hline
\cellcolor[HTML]{34CDF9}{\color[HTML]{000000} } & \cellcolor[HTML]{000000}{\color[HTML]{000000} } & \cellcolor[HTML]{F8FF00}{\color[HTML]{000000} } & \cellcolor[HTML]{009901}{\color[HTML]{000000} } & \cellcolor[HTML]{FE0000}{\color[HTML]{000000} } & \cellcolor[HTML]{C242BB}{\color[HTML]{000000} } \\ \hline
{\color[HTML]{000000} Alexander Gauland}        & {\color[HTML]{000000} Thorsten Frei}            & {\color[HTML]{000000} Thomas Hacker}            & {\color[HTML]{000000} Kathrin Göring Eckardt}   & {\color[HTML]{000000} Helge Lindh}              & {\color[HTML]{000000} Dietmar Bartsch}          \\ \hline
{\color[HTML]{000000} Peter Boehringer}         & {\color[HTML]{000000} Alexander Dobrindt}       & {\color[HTML]{000000} Christian Lindner}        & {\color[HTML]{000000} Annalena Baerbock}        & {\color[HTML]{000000} Karl Heinz Brunner}       & {\color[HTML]{000000} Gesine Lötzsch}           \\ \hline
{\color[HTML]{000000} Norbert Kleinwächter}     & {\color[HTML]{000000} Philipp Amthor}           & {\color[HTML]{000000} Konstantin Kuhle}         & {\color[HTML]{000000} Anton Hofreiter}          & {\color[HTML]{000000} Daniela De Ridder}        & {\color[HTML]{000000} Kathrin Vogler}           \\ \hline
{\color[HTML]{000000} Götz Frömming}            & {\color[HTML]{000000} Andrea Lindholz}          & {\color[HTML]{000000} Stephan Thomae}           & {\color[HTML]{000000} Omid Nouripour}           & {\color[HTML]{000000} Rolf Mützenich}           & {\color[HTML]{000000} Heike Hänsel}             \\ \hline
\end{tabular}
\end{table}

-----

# Results

- some plots of the results and maybe some tables showing some cosine distances and overall 'similarity' of fake and original speeches (manifestobera scores)

# Discussion

- what can we conclude from our research? Is there a connection?
- can we confirm/reject the functioning of our approaches (manifestoberta and PCA)
- what might we infer about the workings of GPT based on our research

# References

- should get at least a few pages probably