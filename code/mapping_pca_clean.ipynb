{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar Project: Distance Mapping Using Doc2Vec Embedding and PCA\n",
    "---------------\n",
    "``` \n",
    "\n",
    "Jakob Amann\n",
    "Elias Gabriel Heppner, 1244414\n",
    "Andri Rutschmann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\elias\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Speeches Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Das System kann den angegebenen Pfad nicht finden: '../data/opendiscourse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Define \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/opendiscourse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mgetcwd()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Das System kann den angegebenen Pfad nicht finden: '../data/opendiscourse'"
     ]
    }
   ],
   "source": [
    "#Define \n",
    "os.chdir(\"../data/opendiscourse\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import csv\n",
    "import io\n",
    "\n",
    "zip_file_path = 'sub_speeches.zip'\n",
    "\n",
    "# Name of the CSV file within the zip file\n",
    "csv_file_name = 'sub_speeches.csv'\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Read the CSV file directly into a Pandas DataFrame\n",
    "    with zip_ref.open(csv_file_name) as file:\n",
    "        speeches_df = pd.read_csv(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\elias\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elias\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\elias\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>session</th>\n",
       "      <th>electoral_term</th>\n",
       "      <th>date</th>\n",
       "      <th>document_url</th>\n",
       "      <th>speech_content</th>\n",
       "      <th>politician_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>faction_id</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>full_name</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pol_name</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1053795</td>\n",
       "      <td>206</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>https://dip21.bundestag.de/dip21/btp/19/19206.pdf</td>\n",
       "      <td>\\n\\nHerr Präsident! Liebe Kolleginnen und Koll...</td>\n",
       "      <td>11003608</td>\n",
       "      <td>Joachim</td>\n",
       "      <td>Pfeiffer</td>\n",
       "      <td>4</td>\n",
       "      <td>CDU/CSU</td>\n",
       "      <td>Christlich Demokratische Union Deutschlands/Ch...</td>\n",
       "      <td>[herr, präsident, !, liebe, kolleginnen, und, ...</td>\n",
       "      <td>Joachim_Pfeiffer</td>\n",
       "      <td>[herr, präsident, liebe, kolleginnen, kollegen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1050697</td>\n",
       "      <td>194</td>\n",
       "      <td>19</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>https://dip21.bundestag.de/dip21/btp/19/19194.pdf</td>\n",
       "      <td>\\n\\nSehr geehrte Frau Präsidentin! Liebe Kolle...</td>\n",
       "      <td>11004659</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>Badum</td>\n",
       "      <td>3</td>\n",
       "      <td>Grüne</td>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>[sehr, geehrte, frau, präsidentin, !, liebe, k...</td>\n",
       "      <td>Lisa_Badum</td>\n",
       "      <td>[geehrte, frau, präsidentin, liebe, kolleginne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1052566</td>\n",
       "      <td>202</td>\n",
       "      <td>19</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>https://dip21.bundestag.de/dip21/btp/19/19202.pdf</td>\n",
       "      <td>\\n\\nLieber Kollege Whittaker, vielen Dank für ...</td>\n",
       "      <td>11004801</td>\n",
       "      <td>Sven</td>\n",
       "      <td>Lehmann</td>\n",
       "      <td>3</td>\n",
       "      <td>Grüne</td>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>[lieber, kollege, whittaker, ,, vielen, dank, ...</td>\n",
       "      <td>Sven_Lehmann</td>\n",
       "      <td>[lieber, kollege, whittaker, vielen, dank, fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046545</td>\n",
       "      <td>180</td>\n",
       "      <td>19</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>https://dip21.bundestag.de/dip21/btp/19/19180.pdf</td>\n",
       "      <td>\\n\\nLiebe Bürger! Frau Präsidentin! Meine Dame...</td>\n",
       "      <td>11004761</td>\n",
       "      <td>Leif Erik</td>\n",
       "      <td>Holm</td>\n",
       "      <td>0</td>\n",
       "      <td>AfD</td>\n",
       "      <td>Alternative für Deutschland</td>\n",
       "      <td>[liebe, bürger, !, frau, präsidentin, !, meine...</td>\n",
       "      <td>Leif Erik_Holm</td>\n",
       "      <td>[liebe, bürger, frau, präsidentin, damen, herr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1041775</td>\n",
       "      <td>164</td>\n",
       "      <td>19</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>https://dip21.bundestag.de/dip21/btp/19/19164.pdf</td>\n",
       "      <td>\\n\\nSehr geehrter Herr Präsident! Liebe Kolleg...</td>\n",
       "      <td>11004004</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Aumer</td>\n",
       "      <td>4</td>\n",
       "      <td>CDU/CSU</td>\n",
       "      <td>Christlich Demokratische Union Deutschlands/Ch...</td>\n",
       "      <td>[sehr, geehrter, herr, präsident, !, liebe, ko...</td>\n",
       "      <td>Peter_Aumer</td>\n",
       "      <td>[geehrter, herr, präsident, liebe, kolleginnen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1039125</td>\n",
       "      <td>155</td>\n",
       "      <td>19</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>https://dip21.bundestag.de/dip21/btp/19/19155.pdf</td>\n",
       "      <td>\\n\\nSehr geehrter Herr Präsident! Liebe Kolleg...</td>\n",
       "      <td>11004814</td>\n",
       "      <td>Astrid</td>\n",
       "      <td>Mannes</td>\n",
       "      <td>4</td>\n",
       "      <td>CDU/CSU</td>\n",
       "      <td>Christlich Demokratische Union Deutschlands/Ch...</td>\n",
       "      <td>[sehr, geehrter, herr, präsident, !, liebe, ko...</td>\n",
       "      <td>Astrid_Mannes</td>\n",
       "      <td>[geehrter, herr, präsident, liebe, kolleginnen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1058672</td>\n",
       "      <td>222</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>https://dip21.bundestag.de/dip21/btp/19/19222.pdf</td>\n",
       "      <td>\\n\\nHerr Präsident! Liebe Kolleginnen und Koll...</td>\n",
       "      <td>11004270</td>\n",
       "      <td>Johannes</td>\n",
       "      <td>Fechner</td>\n",
       "      <td>23</td>\n",
       "      <td>SPD</td>\n",
       "      <td>Sozialdemokratische Partei Deutschlands</td>\n",
       "      <td>[herr, präsident, !, liebe, kolleginnen, und, ...</td>\n",
       "      <td>Johannes_Fechner</td>\n",
       "      <td>[herr, präsident, liebe, kolleginnen, kollegen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1040758</td>\n",
       "      <td>160</td>\n",
       "      <td>19</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>https://dip21.bundestag.de/dip21/btp/19/19160.pdf</td>\n",
       "      <td>\\n\\nSehr geehrte Frau Präsidentin! Sehr geehrt...</td>\n",
       "      <td>11004791</td>\n",
       "      <td>Steffen</td>\n",
       "      <td>Kotré</td>\n",
       "      <td>0</td>\n",
       "      <td>AfD</td>\n",
       "      <td>Alternative für Deutschland</td>\n",
       "      <td>[sehr, geehrte, frau, präsidentin, !, sehr, ge...</td>\n",
       "      <td>Steffen_Kotré</td>\n",
       "      <td>[geehrte, frau, präsidentin, geehrte, damen, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1055605</td>\n",
       "      <td>212</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>https://dip21.bundestag.de/dip21/btp/19/19212.pdf</td>\n",
       "      <td>\\n\\nSehr geehrter Herr Präsident! Werte Kolleg...</td>\n",
       "      <td>11004719</td>\n",
       "      <td>Dietmar</td>\n",
       "      <td>Friedhoff</td>\n",
       "      <td>0</td>\n",
       "      <td>AfD</td>\n",
       "      <td>Alternative für Deutschland</td>\n",
       "      <td>[sehr, geehrter, herr, präsident, !, werte, ko...</td>\n",
       "      <td>Dietmar_Friedhoff</td>\n",
       "      <td>[geehrter, herr, präsident, werte, kolleginnen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1054097</td>\n",
       "      <td>206</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>https://dip21.bundestag.de/dip21/btp/19/19206.pdf</td>\n",
       "      <td>\\n\\nSehr geehrter Herr Präsident! Liebe Kolleg...</td>\n",
       "      <td>11004867</td>\n",
       "      <td>Stefan</td>\n",
       "      <td>Rouenhoff</td>\n",
       "      <td>4</td>\n",
       "      <td>CDU/CSU</td>\n",
       "      <td>Christlich Demokratische Union Deutschlands/Ch...</td>\n",
       "      <td>[sehr, geehrter, herr, präsident, !, liebe, ko...</td>\n",
       "      <td>Stefan_Rouenhoff</td>\n",
       "      <td>[geehrter, herr, präsident, liebe, kolleginnen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_x  session  electoral_term        date  \\\n",
       "0    1053795      206              19  2021-01-28   \n",
       "1    1050697      194              19  2020-11-25   \n",
       "2    1052566      202              19  2020-12-17   \n",
       "3    1046545      180              19  2020-10-01   \n",
       "4    1041775      164              19  2020-05-29   \n",
       "..       ...      ...             ...         ...   \n",
       "195  1039125      155              19  2020-04-22   \n",
       "196  1058672      222              19  2021-04-16   \n",
       "197  1040758      160              19  2020-05-14   \n",
       "198  1055605      212              19  2021-02-25   \n",
       "199  1054097      206              19  2021-01-28   \n",
       "\n",
       "                                          document_url  \\\n",
       "0    https://dip21.bundestag.de/dip21/btp/19/19206.pdf   \n",
       "1    https://dip21.bundestag.de/dip21/btp/19/19194.pdf   \n",
       "2    https://dip21.bundestag.de/dip21/btp/19/19202.pdf   \n",
       "3    https://dip21.bundestag.de/dip21/btp/19/19180.pdf   \n",
       "4    https://dip21.bundestag.de/dip21/btp/19/19164.pdf   \n",
       "..                                                 ...   \n",
       "195  https://dip21.bundestag.de/dip21/btp/19/19155.pdf   \n",
       "196  https://dip21.bundestag.de/dip21/btp/19/19222.pdf   \n",
       "197  https://dip21.bundestag.de/dip21/btp/19/19160.pdf   \n",
       "198  https://dip21.bundestag.de/dip21/btp/19/19212.pdf   \n",
       "199  https://dip21.bundestag.de/dip21/btp/19/19206.pdf   \n",
       "\n",
       "                                        speech_content  politician_id  \\\n",
       "0    \\n\\nHerr Präsident! Liebe Kolleginnen und Koll...       11003608   \n",
       "1    \\n\\nSehr geehrte Frau Präsidentin! Liebe Kolle...       11004659   \n",
       "2    \\n\\nLieber Kollege Whittaker, vielen Dank für ...       11004801   \n",
       "3    \\n\\nLiebe Bürger! Frau Präsidentin! Meine Dame...       11004761   \n",
       "4    \\n\\nSehr geehrter Herr Präsident! Liebe Kolleg...       11004004   \n",
       "..                                                 ...            ...   \n",
       "195  \\n\\nSehr geehrter Herr Präsident! Liebe Kolleg...       11004814   \n",
       "196  \\n\\nHerr Präsident! Liebe Kolleginnen und Koll...       11004270   \n",
       "197  \\n\\nSehr geehrte Frau Präsidentin! Sehr geehrt...       11004791   \n",
       "198  \\n\\nSehr geehrter Herr Präsident! Werte Kolleg...       11004719   \n",
       "199  \\n\\nSehr geehrter Herr Präsident! Liebe Kolleg...       11004867   \n",
       "\n",
       "    first_name  last_name  faction_id abbreviation  \\\n",
       "0      Joachim   Pfeiffer           4      CDU/CSU   \n",
       "1         Lisa      Badum           3        Grüne   \n",
       "2         Sven    Lehmann           3        Grüne   \n",
       "3    Leif Erik       Holm           0          AfD   \n",
       "4        Peter      Aumer           4      CDU/CSU   \n",
       "..         ...        ...         ...          ...   \n",
       "195     Astrid     Mannes           4      CDU/CSU   \n",
       "196   Johannes    Fechner          23          SPD   \n",
       "197    Steffen      Kotré           0          AfD   \n",
       "198    Dietmar  Friedhoff           0          AfD   \n",
       "199     Stefan  Rouenhoff           4      CDU/CSU   \n",
       "\n",
       "                                             full_name  \\\n",
       "0    Christlich Demokratische Union Deutschlands/Ch...   \n",
       "1                                Bündnis 90/Die Grünen   \n",
       "2                                Bündnis 90/Die Grünen   \n",
       "3                          Alternative für Deutschland   \n",
       "4    Christlich Demokratische Union Deutschlands/Ch...   \n",
       "..                                                 ...   \n",
       "195  Christlich Demokratische Union Deutschlands/Ch...   \n",
       "196            Sozialdemokratische Partei Deutschlands   \n",
       "197                        Alternative für Deutschland   \n",
       "198                        Alternative für Deutschland   \n",
       "199  Christlich Demokratische Union Deutschlands/Ch...   \n",
       "\n",
       "                                                tokens           pol_name  \\\n",
       "0    [herr, präsident, !, liebe, kolleginnen, und, ...   Joachim_Pfeiffer   \n",
       "1    [sehr, geehrte, frau, präsidentin, !, liebe, k...         Lisa_Badum   \n",
       "2    [lieber, kollege, whittaker, ,, vielen, dank, ...       Sven_Lehmann   \n",
       "3    [liebe, bürger, !, frau, präsidentin, !, meine...     Leif Erik_Holm   \n",
       "4    [sehr, geehrter, herr, präsident, !, liebe, ko...        Peter_Aumer   \n",
       "..                                                 ...                ...   \n",
       "195  [sehr, geehrter, herr, präsident, !, liebe, ko...      Astrid_Mannes   \n",
       "196  [herr, präsident, !, liebe, kolleginnen, und, ...   Johannes_Fechner   \n",
       "197  [sehr, geehrte, frau, präsidentin, !, sehr, ge...      Steffen_Kotré   \n",
       "198  [sehr, geehrter, herr, präsident, !, werte, ko...  Dietmar_Friedhoff   \n",
       "199  [sehr, geehrter, herr, präsident, !, liebe, ko...   Stefan_Rouenhoff   \n",
       "\n",
       "                                             tokenized  \n",
       "0    [herr, präsident, liebe, kolleginnen, kollegen...  \n",
       "1    [geehrte, frau, präsidentin, liebe, kolleginne...  \n",
       "2    [lieber, kollege, whittaker, vielen, dank, fra...  \n",
       "3    [liebe, bürger, frau, präsidentin, damen, herr...  \n",
       "4    [geehrter, herr, präsident, liebe, kolleginnen...  \n",
       "..                                                 ...  \n",
       "195  [geehrter, herr, präsident, liebe, kolleginnen...  \n",
       "196  [herr, präsident, liebe, kolleginnen, kollegen...  \n",
       "197  [geehrte, frau, präsidentin, geehrte, damen, h...  \n",
       "198  [geehrter, herr, präsident, werte, kolleginnen...  \n",
       "199  [geehrter, herr, präsident, liebe, kolleginnen...  \n",
       "\n",
       "[200 rows x 15 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gensim\n",
    "import nltk\n",
    "nltk.download('punkt')  # Nur notwendig beim ersten Mal\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define preprocessing function\n",
    "\n",
    "def prep_doc2vec(speech_txts, df):\n",
    "    \n",
    "    def preprocess_speech(speech_txts, bigram=None, trigram=None):\n",
    "        # Tokenization\n",
    "\n",
    "        tokens = word_tokenize(speech_txts, language=\"german\")\n",
    "        \n",
    "        # Lowercasing\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        \n",
    "        # Removing punctuation\n",
    "        tokens = [token for token in tokens if token not in string.punctuation]\n",
    "        # Define parliamentary words\n",
    "        #parl_words = [\"kolleginnen\", \"kollegen\", \"damen\", \"herren\", \"kollege\", \"kollegin\", \"präsident\", \"präsidentin\"]\n",
    "        \n",
    "        # Removing stopwords\n",
    "        stop_words = set(stopwords.words('german'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        #tokens = [token for token in tokens if token not in parl_words]\n",
    "\n",
    "        # Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "        # Apply bigram phrase model if available\n",
    "        if bigram:\n",
    "            tokens = bigram[tokens]\n",
    "        \n",
    "        # Apply trigram phrase model if available\n",
    "        if trigram:\n",
    "            tokens = trigram[tokens]\n",
    "\n",
    "        return tokens\n",
    "\n",
    "\n",
    "    bigram_phrases = Phrases(speech_txts, min_count=1)\n",
    "    bigram = Phraser(bigram_phrases)\n",
    "    trigram_phrases = Phrases(bigram[speech_txts], min_count=1)\n",
    "    trigram = Phraser(trigram_phrases)\n",
    "\n",
    "    df[\"tokenized\"] = [preprocess_speech(doc, bigram=bigram, trigram=trigram) for doc in speech_txts]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "class DataFrameIterator(object):\n",
    "    def __init__(self, dataframe, party_col=None, name_col=None, pos_col=None, gov_col=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.party_col = party_col\n",
    "        self.name_col = name_col\n",
    "        self.pos_col = pos_col\n",
    "        self.gov_col = gov_col\n",
    "\n",
    "    def __iter__(self):\n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            tags = []\n",
    "            if self.party_col is not None:\n",
    "                tags.append(str(row[self.party_col]))\n",
    "            if self.name_col is not None:\n",
    "                tags.append(str(row[self.name_col]))\n",
    "            if self.pos_col is not None:\n",
    "                tags.append(str(row[self.pos_col]))\n",
    "            if self.gov_col is not None:\n",
    "                tags.append(str(row[self.gov_col]))\n",
    "            words = row['tokenized']\n",
    "            yield TaggedDocument(words=words, tags=tags)\n",
    "\n",
    "# Initialize Doc2Vec model\n",
    "model = Doc2Vec(vector_size=200, window=20, min_count=50, workers=8, epochs=5)\n",
    "\n",
    "# Tag documents using party and/or name as metadata\n",
    "# If you only want to use polname, set party_column=None\n",
    "# If you only want to use abbreviation, set name_column=None\n",
    "# ...and so on\n",
    "tagged_data = DataFrameIterator(filtered_df, party_col='abbreviation', name_col=None, pos_col=None, gov_col=None)\n",
    "\n",
    "# Build vocabulary\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "# Train the model\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Assuming you have already trained your Doc2Vec model and stored it in the variable `model`\n",
    "def run_pca(df, title):\n",
    "    \n",
    "    # Infer vectors for each document in your corpus\n",
    "    document_vectors = [model.infer_vector(doc) for doc in df[\"tokenized\"]]\n",
    "\n",
    "    # Convert the list of document vectors into a numpy array\n",
    "    document_vectors_np = np.array(document_vectors)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)  # You can change the number of components as needed\n",
    "    document_embeddings = pca.fit_transform(document_vectors_np)\n",
    "\n",
    "    # Get the feature names (words) from the Doc2Vec model\n",
    "    feature_names = model.wv.index_to_key\n",
    "\n",
    "    # Create a dictionary to store word loadings\n",
    "    word_loadings = dict(zip(feature_names, pc_loadings))\n",
    "\n",
    "    # Sort the words based on their loadings\n",
    "    sorted_words = sorted(word_loadings.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "    # Get the top 10 words with highest loadings\n",
    "    num_top_words = 10\n",
    "    \n",
    "    pc_loadings = pca.components_[0]\n",
    "    pc_loads = pd.DataFrame(columns=['high', 'low'])\n",
    "\n",
    "    # Get the top words with highest loadings\n",
    "    top_words_highest_loadings = [word for word, _ in sorted_words[:num_top_words]]\n",
    "\n",
    "    # Get the top words with lowest loadings\n",
    "    top_words_lowest_loadings = [word for word, _ in sorted_words[-num_top_words:]]\n",
    "\n",
    "    # Add the lists of top words to the DataFrame\n",
    "    pc_loads['high'] = top_words_highest_loadings\n",
    "    pc_loads['low'] = top_words_lowest_loadings\n",
    "    pc_loads['pc'] = 1\n",
    "\n",
    "    ##Plot\n",
    "\n",
    "    # Define custom colors for each abbreviation\n",
    "    abbreviation_colors = {\n",
    "        'CDU/CSU': 'black',\n",
    "        'DIE LINKE.': 'pink',\n",
    "        'SPD': 'red',\n",
    "        'AfD':'blue',\n",
    "        'FDP': 'yellow',\n",
    "        'Grüne': 'green',\n",
    "        'not found': 'magenta',\n",
    "    }\n",
    "\n",
    "    # Plot the embeddings with color coding by string categories and custom colors\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(document_embeddings[:, 0], document_embeddings[:, 1], c=filtered_df[\"abbreviation\"].map(abbreviation_colors), alpha=0.7)\n",
    "\n",
    "    # Create custom legend\n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color=color, label=abbreviation, linestyle='') for abbreviation, color in abbreviation_colors.items()]\n",
    "    legend1 = plt.legend(handles=legend_elements, title=\"Abbreviation\", loc='upper right')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Add legend to the plot\n",
    "    plt.gca().add_artist(legend1)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words with highest loadings:\n",
      "geehrte: 0.18989089131355286\n",
      "neuen: -0.18954887986183167\n",
      "10: -0.1884608119726181\n",
      "deutlich: 0.17944668233394623\n",
      "euro: -0.1488945037126541\n",
      "jahr: -0.13384661078453064\n",
      "leider: 0.12915381789207458\n",
      "sage: -0.12848737835884094\n",
      "sehen: -0.1232459768652916\n",
      "zwei: -0.12191121280193329\n",
      "\n",
      "Top 10 words with lowest loadings:\n",
      "dafür: 0.006304912734776735\n",
      "„: 0.005805832799524069\n",
      "seit: -0.005448547191917896\n",
      "natürlich: 0.005315979477018118\n",
      "fragen: -0.004989075940102339\n",
      "regierung: 0.004953455179929733\n",
      "großen: 0.003959269728511572\n",
      "endlich: -0.0031430430244654417\n",
      "krise: 0.001831629080697894\n",
      "gilt: 0.0010227259481325746\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic 1: Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subselect for dataframe\n",
    "\n",
    "\n",
    "#turn to list\n",
    "speech_lst = speeches_df[speech_text].tolist()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
